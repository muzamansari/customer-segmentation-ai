1. Project Overview

This project builds an AI-driven customer segmentation system using the RFM (Recency, Frequency, Monetary) framework.

The objective is to identify high-value customers, detect at-risk customers, and support targeted marketing decisions using data-driven segmentation.

The workflow includes:

Data cleaning and transformation using SQL (SQLite)

RFM feature engineering

Preparation for machine learning clustering (KMeans)

Business interpretation of customer segments

2. Business Problem

An online retail company wants to:

Identify its most valuable customers

Detect customers likely to churn

Optimize marketing spend

Improve revenue through segmentation

Raw transaction data alone does not provide actionable insights.
This project transforms transactional data into structured customer intelligence.

3. Dataset

Source: Online Retail Dataset (UK-based non-store retail, 2010–2011)

Total transactions: 541,909

Time period: 01/12/2010 – 09/12/2011

Customers: ~4,300 after cleaning

Columns include:

InvoiceNo

StockCode

Description

Quantity

InvoiceDate

UnitPrice

CustomerID

Country

4. Data Cleaning (SQL)

Data cleaning was performed in SQLite.

The following records were removed:

Transactions with NULL CustomerID

Cancelled invoices (InvoiceNo starting with ‘C’)

Negative quantities (returns)

Zero or negative unit prices

After cleaning:

397,884 valid transaction records remained

5. RFM Feature Engineering

An RFM table was created using SQL aggregation.

Reference date used for recency calculation:
2011-12-10 (one day after the last transaction date).

RFM metrics:

Recency
Number of days since the customer's last purchase.

Frequency
Number of distinct invoices per customer.

Monetary
Total revenue generated by the customer.

Resulting dataset:

~4,300 customers

Recency range: 1 to 374 days



## Machine Learning & Customer Segmentation
Machine Learning & Customer Segmentation (Python Phase)
Objective

The objective of this phase was to transform RFM features into actionable customer segments using machine learning. The goal was not just to cluster customers, but to translate behavioral patterns into strategic business insights.

The segmentation was built using KMeans clustering with proper preprocessing and validation.

Step 1: Load RFM Dataset
import pandas as pd

rfm = pd.read_csv("../data/rfm_table.csv")
rfm.head()

The dataset used here was generated via SQL aggregation and contains:

CustomerID

recency (days since last purchase)

frequency (number of invoices)

monetary (total revenue per customer)

Total customers: 4,338

Step 2: Exploratory Summary
rfm.describe()

Initial inspection revealed strong skewness in the monetary variable:

Maximum monetary value: 280,206

Mean monetary value: 2,054

This indicates heavy outliers, which would distort distance-based clustering.

Step 3: Log Transformation

To reduce skewness and stabilize variance:

import numpy as np

rfm_log = rfm.copy()

rfm_log['recency'] = np.log1p(rfm_log['recency'])
rfm_log['frequency'] = np.log1p(rfm_log['frequency'])
rfm_log['monetary'] = np.log1p(rfm_log['monetary'])

log1p() compresses extreme values while preserving relative differences.

This ensures clustering is not dominated by extreme spenders.

Step 4: Feature Scaling

KMeans relies on Euclidean distance. Features must be scaled.

from sklearn.preprocessing import StandardScaler

features = rfm_log[['recency', 'frequency', 'monetary']]

scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)

After scaling:

Mean ≈ 0

Standard deviation ≈ 1

Each feature now contributes equally to clustering.

Step 5: Determine Optimal Number of Clusters (Elbow Method)
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

inertia = []

for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(scaled_features)
    inertia.append(kmeans.inertia_)

plt.plot(range(1, 11), inertia)
plt.xlabel("Number of Clusters")
plt.ylabel("Inertia")
plt.title("Elbow Method")
plt.show()

The elbow curve showed a clear bend at k = 4.

This indicates that four clusters provide an optimal balance between model simplicity and cluster compactness.

Step 6: Final Clustering Model
kmeans = KMeans(n_clusters=4, random_state=42)
rfm['cluster'] = kmeans.fit_predict(scaled_features)

Each customer was assigned to one of four clusters based on behavioral similarity.

Step 7: Cluster Profiling
cluster_summary = rfm.groupby('cluster').agg({
    'recency': 'mean',
    'frequency': 'mean',
    'monetary': 'mean',
    'CustomerID': 'count'
}).rename(columns={'CustomerID': 'customer_count'})

Cluster characteristics:

Low recency → recent buyers

High frequency → loyal buyers

High monetary → high-value customers

Step 8: Business Labeling

Clusters were translated into business-friendly segments:

def label_cluster(row):
    if row['cluster'] == 3:
        return 'VIP'
    elif row['cluster'] == 1:
        return 'Loyal'
    elif row['cluster'] == 0:
        return 'Promising'
    else:
        return 'At Risk'

rfm['segment'] = rfm.apply(label_cluster, axis=1)

Final segments:

VIP

Loyal

Promising

At Risk

Step 9: Revenue Contribution Analysis
segment_summary = rfm.groupby('segment').agg({
    'CustomerID': 'count',
    'monetary': 'sum'
}).rename(columns={'CustomerID': 'customer_count'})

segment_summary['revenue_percentage'] = (
    segment_summary['monetary'] / rfm['monetary'].sum() * 100
)
Results:
Segment	Customers	Revenue Contribution
VIP	717	64.6%
Loyal	1,176	24.2%
At Risk	1,541	6.3%
Promising	904	5.0%
Key Strategic Insights

16% of customers generate 65% of total revenue.

VIP customers are the primary revenue drivers.

Loyal customers represent strong upsell opportunity.

At Risk customers form the largest segment but contribute minimal revenue.

Retention and targeted marketing strategies can significantly impact profitability.

Final Output

The segmented dataset was exported for dashboard integration:

rfm.to_csv("../data/rfm_segmented.csv", index=False)

This file is used for Power BI visualization and executive reporting.

Technical Skills Demonstrated

Data preprocessing and cleaning validation

Skewness handling (log transformation)

Feature scaling

KMeans clustering

Model selection (Elbow Method)

Cluster profiling

Revenue concentration analysis

Business interpretation of ML results

## This is now a complete end-to-end AI segmentation pipeline.

If a recruiter asks:

“Tell me about a machine learning project you built.”

You now have a structured, business-aligned answer.